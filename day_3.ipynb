{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3: Learning Structured Predictors\n",
    "\n",
    "In Day 2, we focused on generative classifiers - HMMs. Today's focus is on discriminative classifiers. Recall that:\n",
    "\n",
    "* **generative classifiers** try to model the probability distribution of the data, $P(X, Y)$;\n",
    "\n",
    "* **discriminative classifiers** only model the conditional probability of each class given the observed data, $P(Y\\,|\\,X)$.\n",
    "\n",
    "In Day 1, we implemented discriminative models for classification tasks. Today, we extend this concept to the classification of _sequential_ data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be using two discriminative classifiers to do part-of-speech tagging:\n",
    "* Conditional Random Fields (CRF) and\n",
    "* Structured Perceptron.\n",
    "\n",
    "Your tasks for this lab session are:\n",
    "\n",
    "* to train a CRF model using two different sets of features (exercises 3.1 and 3.2); \n",
    "* to implement the structured perceptron algorithm (exercise 3.3); \n",
    "* to compare the performance of the Structured Perceptron with that of CRFs (exercise 3.4).\n",
    "\n",
    "** TO DO: explain what the basic and extended features represent **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Fields\n",
    "\n",
    "CRFs are the generalization of the Maximum Entropy classifier for sequences.\n",
    "\n",
    "Objectives:\n",
    "\n",
    "* train a CRF using different feature sets for part-of-speech tagging;\n",
    "* evaluate the model on the training, development and test sets.\n",
    "\n",
    "Files used:\n",
    "\n",
    "* class CRFOnline in lxmls/sequences/crf_online.py file\n",
    "* class PostagCorpus in lxmls/sequences/readers/pos_corpus.py file\n",
    "* class IDFeatures in lxmls/sequences/id_feature.py file\n",
    "* class ExtendedFeatures in lxmls/sequences/extended_feature.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 - Basic feature set\n",
    "\n",
    "Start by training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxmls.sequences.crf_online as crfo\n",
    "import lxmls.readers.pos_corpus as pcc\n",
    "import lxmls.sequences.id_feature as idfc\n",
    "import lxmls.sequences.extended_feature as exfc\n",
    "\n",
    "print \"CRF Exercise\"\n",
    "\n",
    "# Load the corpus\n",
    "corpus = pcc.PostagCorpus()\n",
    "\n",
    "# Load the training, test and development sequences\n",
    "train_seq = corpus.read_sequence_list_conll(\"data/train-02-21.conll\", max_sent_len=10, max_nr_sent=1000)\n",
    "test_seq = corpus.read_sequence_list_conll(\"data/test-23.conll\", max_sent_len=10, max_nr_sent=1000)\n",
    "dev_seq = corpus.read_sequence_list_conll(\"data/dev-22.conll\", max_sent_len=10, max_nr_sent=1000)\n",
    "\n",
    "# Build features\n",
    "feature_mapper = idfc.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()\n",
    "\n",
    "# Train the model\n",
    "# You will receive feedback when each epoch is finished.\n",
    "# Note that running the 20 epochs might take a while.\n",
    "crf_online = crfo.CRFOnline(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "crf_online.num_epochs = 20\n",
    "crf_online.train_supervised(train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, evaluate the model on the various datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions for the various sequences using the trained model.\n",
    "pred_train = crf_online.viterbi_decode_corpus(train_seq)\n",
    "pred_dev = crf_online.viterbi_decode_corpus(dev_seq)\n",
    "pred_test = crf_online.viterbi_decode_corpus(test_seq)\n",
    "\n",
    "# Evaluate and print accuracies\n",
    "eval_train = crf_online.evaluate_corpus(train_seq, pred_train)\n",
    "eval_dev = crf_online.evaluate_corpus(dev_seq, pred_dev)\n",
    "eval_test = crf_online.evaluate_corpus(test_seq, pred_test)\n",
    "print \"CRF - ID Features Accuracy Train: %.3f Dev: %.3f Test: %.3f\"%(eval_train,eval_dev, eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should be similar to this:\n",
    "\n",
    "_CRF - ID Features Accuracy Train: 0.949 Dev: 0.846 Test: 0.858_\n",
    "\n",
    "Compare with the results achieved with the HMM model (0.837 on the test set). Even when using a similar feature set, a CRF yields better results than the HMM from the previous lecture.\n",
    "\n",
    "Perform some error analysis and figure out what are the main errors the tagger is making. Compare them with the errors made by the HMM model. \n",
    "\n",
    "**Hint:** use the methods developed in the previous lecture to help you with the error analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2 - Extended feature set\n",
    "\n",
    "Train the model again, this time using the extended feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build features\n",
    "feature_mapper = exfc.ExtendedFeatures(train_seq)\n",
    "feature_mapper.build_features()\n",
    "\n",
    "# Train the model\n",
    "# You will receive feedback when each epoch is finished.\n",
    "# Note that running the 20 epochs might take a while.\n",
    "crf_online = crfo.CRFOnline(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "crf_online.num_epochs = 20\n",
    "crf_online.train_supervised(train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions for the various sequences using the trained model.\n",
    "pred_train = crf_online.viterbi_decode_corpus(train_seq)\n",
    "pred_dev = crf_online.viterbi_decode_corpus(dev_seq)\n",
    "pred_test = crf_online.viterbi_decode_corpus(test_seq)\n",
    "\n",
    "# Evaluate and print accuracies\n",
    "eval_train = crf_online.evaluate_corpus(train_seq, pred_train)\n",
    "eval_dev = crf_online.evaluate_corpus(dev_seq, pred_dev)\n",
    "eval_test = crf_online.evaluate_corpus(test_seq, pred_test)\n",
    "print \"CRF - ID Features Accuracy Train: %.3f Dev: %.3f Test: %.3f\"%(eval_train,eval_dev, eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should be similar to this:\n",
    "\n",
    "_CRF - Extended Features Accuracy Train: 0.984 Dev: 0.899 Test: 0.894_\n",
    "\n",
    "Compare the errors obtained with the two different feature sets. Do some error analysis: what errors were correct by using more features? Can you think of other features to use to solve the errors you found?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3 - Algorithm implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4 - POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
