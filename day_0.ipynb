{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems to fix in day0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"../lxmls-toolkit/\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy ndarray\n",
    "\n",
    "This section gives several examples in order to facilitate the understanding of these objects.\n",
    "\n",
    "\n",
    "The number of array dimensions in a numpy array is ndim.\n",
    "\n",
    "If ```X``` is a L-ndim array then\n",
    "\n",
    "- ```X[k]``` is a (L-1)-ndim array (sometimes called **slice** from ```X```)\n",
    "\n",
    "\n",
    "### Some examples\n",
    "\n",
    "#### \"vector\" in numpy\n",
    "<pre>\n",
    "    X = np.array([1,2,3])\n",
    "    X.shape # this is (3,)\n",
    "    X.ndim # this is 1\n",
    "    \n",
    "    array([1, 2, 3])\n",
    "</pre>\n",
    "\n",
    " \n",
    "  \n",
    "#### \"matrix\" in numpy\n",
    "\n",
    "<pre>\n",
    "    X = np.array([[1,2,3]])\n",
    "    X.shape # this is (1,3)\n",
    "    X.ndim # this is 2\n",
    "\n",
    "    array([[1, 2, 3]])\n",
    "</pre>\n",
    "\n",
    "\n",
    "\n",
    "#### \"matrix\" in numpy\n",
    "\n",
    "- Our data will be represented in a (M,D) 2-ndim array\n",
    "- Each row of the array is a **datapoint** or **sample** from the dataset\n",
    "- If X is a 2-ndim array each X[k] is a 1-ndim array \n",
    "\n",
    "<pre>\n",
    "    X = np.array([[1,2,3],[4,5,6]])\n",
    "    X.shape # this is (2,3)\n",
    "    X.ndim # this is 2\n",
    "\n",
    "    array([[1, 2, 3],\n",
    "           [4, 5, 6]])    \n",
    "</pre>\n",
    "\n",
    "\n",
    "#### \"tensor\" in numpy\n",
    "\n",
    "- This could make sense when there is a spatial correlation. For example in the case of images.\n",
    "- If X is a 3-ndim array each X[k] is a 2-ndim array \n",
    "\n",
    "<pre>\n",
    "     X = np.array([[[1,2,4],[3,5,4]],[[10,20,40],[30,50,40]]])\n",
    "     X.shape # this is (2,2,3)\n",
    "     X.ndim # this is 2\n",
    "    \n",
    "     array([[[ 1,  2,  4],\n",
    "            [ 3,  5,  4]],\n",
    "            \n",
    "            [[10, 20, 40],\n",
    "             [30, 50, 40]]])\n",
    "</pre>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing numerical approximation of derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "exact gradient evaluated at 10  takes value 20\n",
      "\n",
      "numerical gradient evaluated at 10 takes value 20\n",
      "\n",
      "grad seems well implemented\n"
     ]
    }
   ],
   "source": [
    "def function(x):\n",
    "    return x**2\n",
    "\n",
    "def grad(x):\n",
    "    return 2*x\n",
    "\n",
    "def num_grad(function, x, h =0.0001):\n",
    "    return (function(x + h) - function(x - h))/(2*h)\n",
    "\n",
    "def check_grad(grad, numerical_grad, epsilon=0.00001):\n",
    "    if np.linalg.norm(grad - numerical_grad) < epsilon:\n",
    "        print \"grad seems well implemented\"\n",
    "        \n",
    "point = 10\n",
    "g = grad(point)\n",
    "print \"\\nexact gradient evaluated at\", point, \" takes value\", g\n",
    "\n",
    "num_g = num_grad(function, point)\n",
    "print \"\\nnumerical gradient evaluated at\", point, \"takes value\", g\n",
    "print \"\"\n",
    "check_grad(grad(10), num_grad(function,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing numerical approximation of gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy example of gradient checking\n",
    "\n",
    "- Let us consider $f(x) = x_1^2 + 10  x_2 + 10 $\n",
    "- Compute the gradient of f\n",
    "- Evaluate the gradient of f \n",
    "- Check that the true gradient is close to the numerical gradient in several points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient of f in point is [4, 10]\n",
      "distance between numerical and real gradient is  0.0\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x[0]**2 + 10*x[1]  + 10\n",
    "\n",
    "def grad_f(x):\n",
    "    return [2**x[0], 10]\n",
    "\n",
    "import scipy\n",
    "point = np.array([2,3])\n",
    "\n",
    "print \"gradient of f in point is\", grad_f(point)\n",
    "print \"distance between numerical and real gradient is \", scipy.optimize.check_grad(f, grad_f, point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy example gradient checking function with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import optimize\n",
    "from scipy.optimize import check_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def func(x,params=10):\n",
    "    return x[0]**2 - 0.5 * x[1]**3 *params\n",
    "\n",
    "def grad(x,params=10):\n",
    "    return [2 * x[0], -1.5 * x[1]**2*params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.384185791015625e-07"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_grad(func, grad, [1.5, -1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_f(x):\n",
    "    return [2**x[0], 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.optimize.check_grad(f, grad_f, np.array([2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement your own numerical gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = {\"x\":ones_X, \"y\":son_height}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69646919],\n",
       "       [ 0.28613933]])"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#num_grad_w(f, w, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0.14\n",
    "\n",
    "Consider the linear regression problem (ordinary least squares) on the Galton dataset, with a single response variable\n",
    "$$\n",
    "y = \\textbf{x}^T\\textbf{w} + \\epsilon\n",
    "$$\n",
    "\n",
    "This is a general problem where\n",
    "\n",
    "- $\\textbf{x}$ is a $D$ dimensional vector\n",
    "- $y$ is a scalar\n",
    "\n",
    "\n",
    "The linear regression problem is, given a set \n",
    "$$\n",
    "\\{y^{(m)}\\}_{m=1}^M\n",
    "$$\n",
    "\n",
    "of samples of $y$ and the corresponding $\\textbf{x}^{(m)}$ vectors, estimate $\\textbf{w}$ to minimise the sum of the $\\epsilon$ variables. \n",
    "\n",
    "Traditionally this is solved analytically to obtain a closed form solution (although this is not the way in which it should be computed in this exercise, linear algebra packages have an optimised solver, with numpy, use numpy.linalg.lstsq).\n",
    "\n",
    "\n",
    "We can code the prediction of our linear model using a dot product already implemented\n",
    "in ```np.dot```. In order to do it we can append a column full of ones. \n",
    "\n",
    "#### Notes about the implementation for the galton dataset\n",
    "- We want to model son heights from father heights.\n",
    "\n",
    "\n",
    "- We will denote the data that has the mentioned appended column as ```ones_X```\n",
    "    - ```ones_X.shape``` should have shape ```(928, 2)```\n",
    "\n",
    "\n",
    "- ```ones_x``` will denote a single row of ```ones_X``` which is a $D+1$ dimensional vector\n",
    "  - Notice that ```ones_x``` can be any for of ```ones_X```, for example the k'th row ```\n",
    "  ones_X[k]```.\n",
    "  - It is very important to understand the difference between  ```\n",
    "  ones_X[k]``` and ```ones_X[k:k+1]```. \n",
    "      - ```ones_X[k]``` has ndim 1\n",
    "      - ```ones_X[k:k+1]``` has ndim 2\n",
    "   \n",
    "   \n",
    "- $y$ is a scalar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxmls\n",
    "import lxmls.readers.galton as galton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "galton_data = galton.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#father_height = galton_data[\"father_height\"]\n",
    "#son_height = galton_data[\"son_height\"]\n",
    "\n",
    "father_height = galton_data[:,0].reshape((len(galton_data),1))\n",
    "son_height = galton_data[:,1].reshape((len(galton_data),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((928, 1), (928, 1))"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "father_height.shape, son_height.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append the column full of ones for the bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ones_X = np.hstack((np.ones((father_height.shape[0],1)), father_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 2)"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,  70.5],\n",
       "       [  1. ,  68.5],\n",
       "       [  1. ,  65.5],\n",
       "       ..., \n",
       "       [  1. ,  69.5],\n",
       "       [  1. ,  69.5],\n",
       "       [  1. ,  69.5]])"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = son_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.14\n",
    "\n",
    "\n",
    "##### 0. Complete the function that produces the predictions for a given observation and a set of weights $w_j$ \n",
    "        \n",
    "<pre>\n",
    "def predict(X,w):\n",
    "    ## WRITE HERE\n",
    "    return ##something\n",
    "</pre>\n",
    "\n",
    "#### Predicting using the linear model\n",
    "\n",
    "\n",
    "Let us assume we have a dataset with\n",
    "\n",
    "- $M$ datapoints (number of rows).\n",
    "- $D$ features (number of columns)\n",
    "\n",
    "In order to do this exercise we will add a column full of ones at position 0 and get a $M \\times (D+1)$.\n",
    "\n",
    "The predict function will return the prediction of the linear model given\n",
    "\n",
    "- An input which can be \n",
    "    - A single $ (D+1) \\times 1$ row vector\n",
    "    - A matrix of the form $batch \\times (D+1)$ where $batch$ is the number of rows in the matrix.\n",
    "    \n",
    "- A vector of weights of size $D$\n",
    "\n",
    "Notice that we have created a new column full of ones  to take into account the bias term of the regressor.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,  70.5],\n",
       "       [  1. ,  68.5],\n",
       "       [  1. ,  65.5],\n",
       "       ..., \n",
       "       [  1. ,  69.5],\n",
       "       [  1. ,  69.5],\n",
       "       [  1. ,  69.5]])"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22685145],\n",
       "       [ 0.55131477]])"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.random((2,1))\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 39.09454267],\n",
       "       [ 37.99191314],\n",
       "       [ 36.33796883]])"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(ones_X[0:3],w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X,w):\n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test passed: your predict function seems to be OK \n"
     ]
    }
   ],
   "source": [
    "### test\n",
    "y_hat_3  = np.array([[ 20.8692923 ],\n",
    "                     [ 20.29701363],\n",
    "                     [ 19.43859562]])\n",
    "\n",
    "np.random.seed(123)\n",
    "w = np.random.random((2,1))\n",
    "\n",
    "if np.linalg.norm(y_hat_3 - predict(ones_X[0:3],w))<0.00001:\n",
    "    print \"\\ntest passed: your predict function seems to be OK \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Complete the function that compute the cost function for a given set of data and weights of the linear model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Y, Y_hat):\n",
    "    cost = 0\n",
    "    num_observations = Y.shape[0]\n",
    "    \n",
    "    for y,y_hat in zip(Y, Y_hat):\n",
    "        cost += (y - y_hat)**2\n",
    "        \n",
    "    # vectorized done\n",
    "    # np.mean( (Y_hat - Y)**2, axis=0)\n",
    "    return  cost/num_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "w = np.random.random((2,1))\n",
    "Y_hat = predict(ones_X, w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test passed: your predict function seems to be OK \n"
     ]
    }
   ],
   "source": [
    "### test\n",
    "np.random.seed(123)\n",
    "w = np.random.random((2,1))\n",
    "\n",
    "Y_hat = predict(ones_X, w) \n",
    "\n",
    "if np.linalg.norm( compute_cost(Y_hat, Y)- 2294.68652697)<0.00001:\n",
    "    print \"\\ntest passed: your predict function seems to be OK \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Derive the partial derivative of the error with respecto to a weight $w_j$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_partial_error_wrt_j(X, Y, weights, j ):\n",
    "    return np.mean(2 * (predict(X,weights) - Y) * X[:,[j]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_grad(X, Y, weights):\n",
    "    if X.ndim == 1:\n",
    "        X = np.array([X])\n",
    "        \n",
    "    # assume rows in X are datapoints\n",
    "    num_features = X.shape[1]\n",
    "    num_examples = X.shape[0]\n",
    "    \n",
    "    #grad_acum = np.zeros(num_features)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    #for x,y in zip(X, Y):\n",
    "    #    for j in range(num_features):\n",
    "    #        grad_acum[j] += compute_partial_error_wrt_j(x, y, w, j)\n",
    "    #grad  = (1./ num_examples) * grad_acum\n",
    "    \n",
    "    grad = np.zeros(num_features)\n",
    "    for j in range(num_features):\n",
    "        #X_j = X[:,j].reshape((num_examples,1)\n",
    "        #grad[j] = np.mean(2*(predict(X,w) - Y) * X_j, axis=0)[0]\n",
    "        import pdb;pdb.set_trace()\n",
    "        grad[j] = compute_partial_error_wrt_j(X, Y, weights, j )\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optimizing weights using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(X,w):\n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20.8692923 ],\n",
       "       [ 20.29701363],\n",
       "       [ 19.43859562]])"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(ones_X[0:3],w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 1)"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(ones_X,w).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_partial_error_wrt_j(X, Y, weights, j ):\n",
    "    return np.mean(2 * (predict(X,weights) - Y) * X[:,[j]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Y, Y_hat):\n",
    "    return np.mean( (Y_hat - Y)**2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w):\n",
    "    \"\"\"\n",
    "    MSE\n",
    "    \"\"\"\n",
    "    predictions = np.dot(x, w)\n",
    "    return np.mean((predictions-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_gradient(X, Y, weights):\n",
    "    if X.ndim == 1:\n",
    "        X = np.array([X])\n",
    "        \n",
    "    # assume rows in X are datapoints\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    grad = np.zeros((num_features,1))\n",
    "    for j in range(num_features):\n",
    "        grad[j] = compute_partial_error_wrt_j(X, Y, weights, j )\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient checking\n",
    "\n",
    "We want to ensure that the computation of the cost with respect to the weights is correct. \n",
    "\n",
    "We will build a function that \n",
    "\n",
    "- Takes as input a function ``func`` and a point where we will evaluate the gradient of ``func``.\n",
    "- Computes an approximation of the gradient of a given function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_grad_w(func, w, x, y ,e = 1e-5):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the func with respect to w.\n",
    "    The function returns a gradient vector of the same size as w\n",
    "    \"\"\"    \n",
    "    dim = w.shape[0]\n",
    "    grads = []\n",
    "    perturbation_vector  = np.zeros(w.shape)\n",
    "    \n",
    "    for i in range(dim):\n",
    "        # Perturbate the current dimension\n",
    "        perturbation_vector[i] = e\n",
    "        \n",
    "        # Compute the slope: (point+epsilon - point-epsilon)/2epsilon\n",
    "        err_a = func(x, y, w + perturbation_vector)\n",
    "        err_b = func(x, y, w - perturbation_vector)\n",
    "        grad = (err_a - err_b) / (2*e)\n",
    "        perturbation_vector[i] = 0\n",
    "\n",
    "        grads.append(grad)\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -95.69268136],\n",
       "       [-6538.89239773]])"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = ones_X.shape[1] \n",
    "np.random.seed(123)\n",
    "weights = np.random.random((num_features,1))\n",
    "\n",
    "## grad using exact formula\n",
    "exact_gradient = compute_gradient(ones_X, son_height, weights)\n",
    "exact_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-95.692681361470008, -6538.892397725248]"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_grad = num_grad_w(compute_cost, weights, x=ones_X, y=son_height)\n",
    "num_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "norm() takes at least 1 argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-761-d2ea802a99ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: norm() takes at least 1 argument (0 given)"
     ]
    }
   ],
   "source": [
    "np.linalg.norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given w_j\n",
    "cost_evolution = []\n",
    "def gradient_descent(num_iterations, X, Y, learning_rate=0.0001):\n",
    "    # add column full of ones to X this allow us to take into \n",
    "    # account an offset (or bias) term for the linear model\n",
    "    num_features = X.shape[1] \n",
    "    weights = np.random.random((num_features,1))\n",
    "    \n",
    "    for it in range(num_iterations):\n",
    "        weights = weights - learning_rate * compute_gradient(X, Y, weights)\n",
    "        Y_hat = predict(X,weights)\n",
    "        #cost = compute_cost(Y,Y_hat)\n",
    "        cost = compute_cost(Y,X,weights)\n",
    "        cost_evolution.append(cost)\n",
    "        sys.stdout.write(\"\\rw_hat\" + str(weights[0]) +\" \"+ str(weights[1]) + \\\n",
    "                         \" cost iter \" +  str(it) + \" is: \" + str(cost[0]) )\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    w_hat = weights\n",
    "    return w_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (928,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-708-9efe69ad075b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#  sys.stdout.write(\"\\rw_hat\" + str(weights) + \"cost iter \" +  str(it) + \" is: \" + str(cost[0]) )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mw_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-707-d754fe575201>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(num_iterations, X, Y, learning_rate)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mY_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#cost = compute_cost(Y,Y_hat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcost_evolution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\rw_hat\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m                          \u001b[0;34m\" cost iter \"\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-695-c646ab550550>\u001b[0m in \u001b[0;36mcompute_cost\u001b[0;34m(x, y, w)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (928,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "weights = np.random.random((2,1))/10\n",
    "weights[0] = 0\n",
    "#  sys.stdout.write(\"\\rw_hat\" + str(weights) + \"cost iter \" +  str(it) + \" is: \" + str(cost[0]) )\n",
    "\n",
    "w_hat = gradient_descent(1000, ones_X, Y,learning_rate = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_hat_lstsq = np.linalg.lstsq(a=ones_X, b= son_height)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23.94153018],\n",
       "       [  0.64629058]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_hat_lstsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error map\n",
    "\n",
    "for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11545c290>]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11545c110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(father_height,son_height, \".\")\n",
    "plt.title(\"We nailed it??\")\n",
    "maxim, minim = int(np.max(father_height)), int(np.min(father_height))\n",
    "xvals = [vec for vec in np.array(range(minim-1, maxim+1)) ]\n",
    "\n",
    "# Gradient descent solution\n",
    "yvals = [ w_hat[1]  * xval + w_hat[0] for xval in xvals]\n",
    "\n",
    "# solution from closed form\n",
    "yvals2 = [ w_hat_lstsq[1]  * xval + w_hat_lstsq[0] for xval in xvals]\n",
    "\n",
    "plt.plot(xvals, yvals, '--', c='k',linewidth=2)\n",
    "plt.plot(xvals, yvals2, '--', c='r',linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add jitter to  see points that are \"superposed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x116324950>]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf8qccM9l7+dyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11506d6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(father_height+np.random.random(father_height.shape)/2.,\n",
    "         son_height+np.random.random(father_height.shape)/2., \".\")\n",
    "plt.title(\"We nailed it??\")\n",
    "maxim, minim = int(np.max(father_height)), int(np.min(father_height))\n",
    "xvals = [vec for vec in np.array(range(minim-1, maxim+1)) ]\n",
    "\n",
    "# Gradient descent solution\n",
    "yvals = [ w_hat[1]  * xval + w_hat[0] for xval in xvals]\n",
    "\n",
    "# solution from closed form\n",
    "yvals2 = [ w_hat_lstsq[1]  * xval + w_hat_lstsq[0] for xval in xvals]\n",
    "\n",
    "plt.plot(xvals, yvals, '--', c='k',linewidth=2)\n",
    "plt.plot(xvals, yvals2, '--', c='r',linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Checking gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.3081896552 1.78637013924\n",
      "68.0884698276 2.51658435116\n",
      "68.1983297414 2.18500039728\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import lxmls.readers\n",
    "\n",
    "galton_data = galton.load()\n",
    "fathers = galton_data[:,0]\n",
    "sons = galton_data[:,1]\n",
    "\n",
    "print fathers.mean(), fathers.std()\n",
    "print sons.mean(), sons.std()\n",
    "print galton_data.ravel().mean(), galton_data.ravel().std()\n",
    "\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "x = np.hstack([fathers[:, None], np.ones([fathers.shape[0], 1])])\n",
    "y = sons[:, None]\n",
    "w = np.array([[0.96], [0.4]]).reshape(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(x, y, w):\n",
    "    \"\"\"\n",
    "    MSE\n",
    "    \"\"\"\n",
    "    predictions = np.dot(x, w)\n",
    "    return np.mean((predictions-y)**2)\n",
    "\n",
    "\n",
    "def error_grad(x, y, w):\n",
    "    \"\"\"\n",
    "    Gradient for error w.r.t. w\n",
    "    \"\"\"\n",
    "    assert x.ndim == 2, 'x should be a matrix'    \n",
    "    assert y.ndim == 2, 'y should be a matrix'\n",
    "    assert w.ndim == 2, 'w should be a matrix'\n",
    "    num_features = x.shape[1]\n",
    "    grad = np.zeros([num_features, 1])\n",
    "    for j in range(num_features):\n",
    "        grad[j] = np.mean(2*(np.dot(x, w)-y)*x[:, [j]], axis=0)\n",
    "    return grad\n",
    "\n",
    "\n",
    "def num_grad_w(func, w,e = 1e-5):\n",
    "#def num_grad_w(func, w, e = 1e-5, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the func with respect to w.\n",
    "    \n",
    "    The function returns a gradient vector of the same size as w\n",
    "    \"\"\"\n",
    "    dim = w.shape[0]\n",
    "    grads = []\n",
    "    perturbation_vector  = np.zeros(w.shape)\n",
    "    \n",
    "    for i in range(dim):\n",
    "        # Perturbate the current dimension\n",
    "        perturbation_vector[i] = e\n",
    "        \n",
    "        # Compute the slope: (point+epsilon - point-epsilon)/2epsilon\n",
    "        err_a = func(x, y, w + perturbation_vector)\n",
    "        err_b = func(x, y, w - perturbation_vector)\n",
    "        grad = (err_a - err_b) / (2*e)\n",
    "        #perturbation_vector[i] = 0\n",
    "\n",
    "        grads.append(grad)\n",
    "    return np.array(grads).reshape(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.random(123)\n",
    "weights = np.random.random((num_features,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -31.33644117],\n",
       "       [-2139.79476767]])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_grad(ones_X, son_height, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -31.33644117],\n",
       "       [-2139.79476767]])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient(ones_X, son_height, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5983.56292552],\n",
       "       [-6071.13130885]])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_grad_w(error,  weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NO see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def numerical_grad(X, Y, weights, epsilon = 0.00001):\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    Y_hat_plus = predict(X,weights + epsilon)\n",
    "    Y_hat_minus = predict(X,weights - epsilon)\n",
    "\n",
    "    numerical_grad = (compute_cost(Y, Y_hat_plus) - compute_cost(Y, Y_hat_minus))/ (2*epsilon)\n",
    "    \n",
    "    #numerical_grad = np.zeros(num_features)\n",
    "    #for j in range(num_features):\n",
    "    #    w_plus = w\n",
    "    #    w_plus[j] += epsilon\n",
    "    #    w_minus = w\n",
    "    #    w_minus[j] -= epsilon\n",
    "    #    cost_plus = compute_cost(X, Y, w_plus)\n",
    "    #    cost_minus = compute_cost(X, Y, w_minus)\n",
    "    #    numerical_grad[j] = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "    return numerical_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_checking(grad, numerical_grad, epsilon=0.00001):\n",
    "    diff = np.linalg.norm(grad - numerical_grad)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "w = np.random.random((2,1))\n",
    "\n",
    "grad = compute_grad(ones_X, son_height, w)\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_grad = numerical_grad(ones_X, son_height, w)\n",
    "num_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grad_checking(ones_X, son_height, np.random.random(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# given w_j\n",
    "cost_evolution = []\n",
    "def gradient_descent(num_iterations, X, Y, learning_rate=0.001):\n",
    "    # add column full of ones to X this allow us to take into \n",
    "    # account an offset (or bias) term for the linear model\n",
    "    X = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "        \n",
    "    num_features = X.shape[1] \n",
    "    num_examples = X.shape[0]\n",
    "    weights = np.random.random(num_features)\n",
    "    \n",
    "    for it in range(num_iterations):\n",
    "        weights = weights - learning_rate * compute_grad(X, Y, weights)\n",
    "        cost = compute_cost(X,Y,weights)\n",
    "        cost_evolution.append(cost)\n",
    "        sys.stdout.write(\"\\rcost iter \" +  str(it) + \" is: \" + str(cost[0]) )\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    w_hat = weights\n",
    "    return w_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-35-8fd3d02ee747>(21)compute_grad()\n",
      "-> grad[j] = compute_partial_error_wrt_j(X, Y, weights, j )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-e90cfb7e8cff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfather_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mson_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-f06aea7afe2f>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(num_iterations, X, Y, learning_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcompute_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcost_evolution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-8fd3d02ee747>\u001b[0m in \u001b[0;36mcompute_grad\u001b[0;34m(X, Y, weights)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#grad[j] = np.mean(2*(predict(X,w) - Y) * X_j, axis=0)[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_partial_error_wrt_j\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-8fd3d02ee747>\u001b[0m in \u001b[0;36mcompute_grad\u001b[0;34m(X, Y, weights)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#grad[j] = np.mean(2*(predict(X,w) - Y) * X_j, axis=0)[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_partial_error_wrt_j\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/pdb.pyc\u001b[0m in \u001b[0;36muser_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_mainpyfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbp_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbp_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/pdb.pyc\u001b[0m in \u001b[0;36minteraction\u001b[0;34m(self, frame, traceback)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_stack_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmdloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/cmd.pyc\u001b[0m in \u001b[0;36mcmdloop\u001b[0;34m(self, intro)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_rawinput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EOF'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         )\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w_hat = gradient_descent(10, father_height, son_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1163b5dd0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEZCAYAAAC0HgObAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzHL1/wFDVydsZB3aAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115145590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_evolution)\n",
    "plt.title(\"Evolution of the error per epoch\")\n",
    "plt.ylabel(\"Error (MSE) value\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the np.linalg.lstsq function and compare to your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23334687],\n",
       "       [ 0.99309302]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23.94153018],\n",
       "       [  0.64629058]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_hat_lstsq = np.linalg.lstsq(ones_X, son_height)[0]\n",
    "w_hat_lstsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot the regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
